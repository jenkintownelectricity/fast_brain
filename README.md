# Fast Brain LPU

**Ultra-fast inference engine for HIVE215 Voice Assistants**

Fast Brain is a custom Language Processing Unit (LPU) designed to make AI voice agents experts in their fields through a skills system, powered by Groq's lightning-fast inference (~80ms TTFB, 200+ tok/s).

---

## Vision

> "I want to make the brain a place where my agents are experts in their perspective fields using skills builder. Can I not upload a lot of info to make them smart and then the LPU will make it fast?"

**Answer: YES.** Fast Brain combines:
- **Skills Database** - Domain-specific system prompts + knowledge bases
- **Groq Backend** - Llama 3.3 70B at 800 tok/s native speed
- **Modal Deployment** - Serverless, auto-scaling, always warm

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              FAST BRAIN LPU                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚   [User Query] â”€â”€â–º [Skill Selector] â”€â”€â–º [System Prompt Builder] â”€â”€â–º [Groq API]  â”‚
â”‚                           â”‚                      â”‚                      â”‚        â”‚
â”‚                           â–¼                      â–¼                      â–¼        â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                    â”‚   Skills    â”‚        â”‚ Knowledge â”‚         â”‚  Llama    â”‚   â”‚
â”‚                    â”‚  Database   â”‚   +    â”‚   Base    â”‚   =     â”‚ 3.3 70B   â”‚   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                        â”‚        â”‚
â”‚                                                                        â–¼        â”‚
â”‚                                                              [Fast Response]    â”‚
â”‚                                                              ~80ms TTFB         â”‚
â”‚                                                              200+ tok/s         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Features

### Core Features

| Feature | Status | Description |
|---------|--------|-------------|
| Groq Backend | âœ… Live | Llama 3.3 70B via Groq API |
| Skills System | âœ… Live | Built-in + custom skills |
| Knowledge Base | âœ… Live | Per-skill knowledge items |
| OpenAI-Compatible API | âœ… Live | Drop-in replacement |
| Modal Deployment | âœ… Live | Serverless on Modal |
| Dashboard Integration | âœ… Live | Full management UI |

### Built-in Skills

| Skill ID | Name | Use Case |
|----------|------|----------|
| `general` | General Assistant | Default helpful assistant |
| `receptionist` | Professional Receptionist | Phone answering, call handling |
| `electrician` | Electrician Assistant | Electrical services, scheduling |
| `plumber` | Plumber Assistant | Plumbing services, emergencies |
| `lawyer` | Legal Intake Assistant | Legal intake, confidential |

### Dashboard Features

| Feature | Tab | Description |
|---------|-----|-------------|
| System Status | Dashboard | Real-time status for Fast Brain, Groq, Hive215, Modal |
| Skills Manager | Skills Manager | List, create, delete skills |
| Skill Selector | Test Chat | Dropdown to select active skill |
| Integration Checklist | Hive215 Integration | Step-by-step progress tracker |
| Architecture Diagram | Hive215 Integration | Visual pipeline documentation |

---

## Performance

### Current Metrics (Groq Backend)

| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| TTFB | <100ms | ~80ms | âœ… Met |
| Throughput | >200 tok/s | ~200 tok/s | âœ… Met |
| Cold Start | <5s | ~3s | âœ… Met |

### Comparison

| Provider | TTFB | Throughput | Cost |
|----------|------|------------|------|
| **Fast Brain (Groq)** | ~80ms | 200 tok/s | Free tier available |
| OpenAI GPT-4 | ~500ms | 50 tok/s | $$$$ |
| Anthropic Claude | ~400ms | 80 tok/s | $$$ |
| Local BitNet | ~10s+ | 5 tok/s | CPU only |

---

## API Reference

### Base URL
```
https://[your-username]--fast-brain-lpu.modal.run
```

### Endpoints

#### Health Check
```bash
GET /health

Response:
{
  "status": "healthy",
  "model_loaded": true,
  "skills_available": ["general", "receptionist", "electrician", "plumber", "lawyer"],
  "version": "2.0.0",
  "backend": "groq-llama-3.3-70b"
}
```

#### List Skills
```bash
GET /v1/skills

Response:
{
  "skills": [
    {"id": "receptionist", "name": "Professional Receptionist", "description": "..."},
    ...
  ]
}
```

#### Create Custom Skill
```bash
POST /v1/skills
Content-Type: application/json

{
  "skill_id": "my_business",
  "name": "My Business Assistant",
  "description": "Expert in my business services",
  "system_prompt": "You are an AI assistant for My Business...",
  "knowledge": ["Pricing: $100-500", "Hours: 9am-5pm", "Service area: Philadelphia"]
}
```

#### Chat Completion (OpenAI-compatible)
```bash
POST /v1/chat/completions
Content-Type: application/json

{
  "messages": [
    {"role": "system", "content": "You are a helpful assistant"},
    {"role": "user", "content": "Hello!"}
  ],
  "max_tokens": 256,
  "temperature": 0.7,
  "skill": "receptionist",
  "user_profile": "Acme Electric - Licensed electrician in Philadelphia"
}

Response:
{
  "id": "chatcmpl-...",
  "choices": [{"message": {"role": "assistant", "content": "..."}}],
  "metrics": {
    "ttfb_ms": 79.7,
    "total_time_ms": 557.2,
    "tokens_per_sec": 213.2
  },
  "skill_used": "receptionist"
}
```

---

## Deployment

### Prerequisites
- Modal account (free tier works)
- Groq API key (free at console.groq.com)
- Python 3.11

### Deploy to Modal

1. **Install Modal CLI**
```bash
pip install modal
modal token new
```

2. **Set up Groq API key as Modal secret**
```bash
modal secret create groq-api-key GROQ_API_KEY=your_key_here
```

3. **Deploy**
```bash
modal deploy fast_brain/deploy_groq.py
```

4. **Get your URL**
```
https://[your-username]--fast-brain-lpu.modal.run
```

### Local Testing

```bash
# Set Groq API key
export GROQ_API_KEY=your_key_here

# Run locally
python fast_brain/deploy_groq.py
# Server at http://localhost:8000
```

---

## Files

```
fast_brain/
â”œâ”€â”€ deploy_groq.py      # Main deployment (Groq backend) â† USE THIS
â”œâ”€â”€ deploy_bitnet.py    # BitNet attempt (CPU too slow)
â”œâ”€â”€ deploy_simple.py    # Stub for testing
â”œâ”€â”€ deploy.py           # Original BitNet design
â”œâ”€â”€ model.py            # BitNet model wrapper
â”œâ”€â”€ client.py           # Python client
â”œâ”€â”€ config.py           # Configuration
â””â”€â”€ requirements.txt    # Dependencies

unified_dashboard.py    # Full management dashboard
README.md               # This file
HIVE215_INTEGRATION.md  # Integration guide for Hive215 team
```

---

## Dashboard

### Running the Dashboard

```bash
pip install flask flask-cors httpx
python unified_dashboard.py
# Opens at http://localhost:5000
```

### Fast Brain Tab

The dashboard has a dedicated **Fast Brain** tab with sub-tabs:

1. **Dashboard** - System status, metrics, configuration
2. **Skills Manager** - Create/edit/delete skills
3. **Test Chat** - Test with skill selector
4. **Hive215 Integration** - Checklist and setup guide

---

## Roadmap

### Completed âœ…

- [x] Groq backend integration
- [x] Skills database with built-in skills
- [x] Custom skill creation
- [x] Knowledge base per skill
- [x] OpenAI-compatible API
- [x] Modal serverless deployment
- [x] Dashboard with skills management
- [x] System status indicators
- [x] Hive215 integration checklist

### In Progress ğŸ”„

- [ ] Streaming responses (SSE)
- [ ] Skill training from documents
- [ ] Voice-specific optimizations

### Planned ğŸ“‹

- [ ] RAG with vector embeddings
- [ ] Multi-turn conversation memory
- [ ] A/B testing for skill prompts
- [ ] Analytics dashboard
- [ ] Webhook notifications
- [ ] Direct Supabase skill sync

### Future Ideas ğŸ’¡

- [ ] Fine-tuned models per skill
- [ ] Voice cloning integration
- [ ] Real-time skill switching mid-call
- [ ] Sentiment-based skill adaptation

---

## Development

### Current Branch
```
claude/fast-brain-streaming-018wsUb2vztjfkc8EGVQ9t8j
```

### Recent Commits
```
fc4edbf Add skills management UI, status indicators, and Hive215 integration
b63d07f Add Groq-powered Fast Brain with Skills Layer
8c156ec Disable CUDA completely to fix BitNet inference
00874e2 Add real BitNet LPU deployment with HuggingFace transformers
940782d Update dashboard to use fast-brain-lpu endpoints
```

### Merge to Main
```bash
git checkout main
git merge claude/fast-brain-streaming-018wsUb2vztjfkc8EGVQ9t8j
git push origin main
```

---

## Troubleshooting

### "503 Service Unavailable"
- Check Modal deployment: `modal app list`
- Verify Groq API key is set in Modal secrets

### "Groq client not initialized"
- Ensure `groq-api-key` secret exists in Modal
- Check Modal logs: `modal app logs fast-brain-lpu`

### Slow responses
- First request warms the container (~3s)
- Subsequent requests should be ~80ms TTFB

### Skills not syncing
- Dashboard creates skills locally first
- Skills sync to LPU on next request
- Check LPU health endpoint for skill count

---

## License

MIT

---

## Contact

Part of the HIVE215 project - AI Phone Assistant Platform

Built with Groq, Modal, and Claude Code
